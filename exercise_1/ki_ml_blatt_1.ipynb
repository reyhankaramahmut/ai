{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PohCF88YwWgk"
      },
      "source": [
        "# Aufgaben Blatt 4 KI Machine Learning I\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9sieFkrwWgm"
      },
      "source": [
        "## Aufgabe 1 (Lineare Regression)\n",
        "\n",
        "Bearbeiten Sie die Aufgabe https://github.com/oduerr/ki/blob/main/linear_regression/lr_gradient_descent.ipynb\n",
        "\n",
        "Versuchen Sie den Code zu verstehen und machen die kleineren Aufgaben, die in dem notebook besprochen werden."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hr2BSdsNwWgm"
      },
      "source": [
        "## Aufgabe 2 (Titanic)\n",
        "In dieser Aufgabe nehmen Sie an der Titanic Challenge (https://www.kaggle.com/c/titanic) teil. Sie können die Aufgabe am eigenen PC lösen oder direkt in Kaggle lösen. Die Daten liegen auch auf Moodle. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-_0tiX-wWgm"
      },
      "source": [
        "a) Lesen Sie die Trainingsdaten ein und teilen Sie sie in ein Validierungsdatenset (20%) und in ein eigentliches Trainigsdatenset (80%) auf. Finden Sie auf dem Trainigsdatenset eine Regel für das Überleben alleine aufgrund der Klasse des Tickets (Pclass). Wenden Sie diese Regel auf die Validierungsdaten an. Wie gut ist die Genauigkeit (Anteil der korrekten Klassifikationen) auf den Validierungsdaten?  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sklearn'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m  \u001b[38;5;66;03m# data processing, CSV file I/O (e.g. pd.read_csv)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
          ]
        }
      ],
      "source": [
        "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGm0-jEawWgn"
      },
      "outputs": [],
      "source": [
        "titanic_data = pd.read_csv(\"titanic/train.csv\")\n",
        "\n",
        "X = titanic_data\n",
        "y = titanic_data[\"Survived\"]\n",
        "\n",
        "X_data_train, X_data_test, y_data_train, y_data_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=20\n",
        ")\n",
        "\n",
        "# survived_by_pclass = X.groupby(\"Pclass\")[\"Survived\"].mean()\n",
        "crosstab = pd.crosstab(X_data_train[\"Pclass\"], X_data_train[\"Survived\"]).rename(\n",
        "    columns={0: \"not survived\", 1: \"survived\"}\n",
        ")\n",
        "sorted_crosstab = crosstab.sort_values(by=\"survived\", ascending=False)\n",
        "top_pclass = sorted_crosstab.iloc[0].name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAb6YDtTwWgn"
      },
      "source": [
        "b) Wenden Sie die Regel aus a) auf die Testdaten an und laden Sie Ihre Lösung hoch. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SeplTB8SwWgo",
        "outputId": "98e2e1d5-0b85-4bb6-beb5-25e200b94913"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your submission was successfully saved!\n"
          ]
        }
      ],
      "source": [
        "#############################################\n",
        "# Hinweise zum rausschreiben\n",
        "pred_survived = X_data_test[\"Pclass\"].apply(\n",
        "    lambda pclass: 1 if pclass == int(top_pclass) else 0\n",
        ")\n",
        "accuracy = accuracy_score(y_data_test, pred_survived)\n",
        "print(\"accuracy: \" + str(accuracy))\n",
        "\n",
        "output = pd.DataFrame(\n",
        "    {\"PassengerId\": X_data_test.PassengerId, \"Survived\": pred_survived}\n",
        ")\n",
        "output.to_csv(\"my_submission.csv\", index=False)\n",
        "print(\"Your submission was successfully saved!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0YqDhK3wWgp"
      },
      "source": [
        "c) Logistische Regression mit Pclass\n",
        "\n",
        "Trainieren Sie eine logistische Regression mit den Variablen 'Pclass'. Verwenden Sie die Klasse `sklearn.linear_model.LogisticRegression`. Berechnen Sie die Accuracy auf dem Validierungsset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = LogisticRegression()\n",
        "x_train = np.array(X_data_train[\"Pclass\"]).reshape(-1, 1)\n",
        "x_test = np.array(X_data_test[\"Pclass\"]).reshape(-1, 1)\n",
        "y_train = np.array(y_data_train)\n",
        "y_test = np.array(y_data_test)\n",
        "model.fit(x_train, y_train)\n",
        "y_pred = model.predict(x_test)\n",
        "print(\"accuracy (model.score): \" + str(model.score(x_test, y_test)))\n",
        "print(\"accuracy (accuracy_score): \" + str(accuracy_score(y_test, y_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-xC04XswWgp"
      },
      "source": [
        "d) Coding / Feature engineering \n",
        "\n",
        "d.i) Missing Values:\n",
        "\n",
        "Verwenden Sie nun weitere Features. Die Variable Age enthält Missing values, die Sie durch folgenden code ersetzen können (was passiert da?)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6i9qi9ywwWgq"
      },
      "outputs": [],
      "source": [
        "# Ersetzt alle fehlenden Werte in der Spalte \"age\" in dem DataFrame mit dem\n",
        "# Medianwert aller vorhandenen Werte in der Spalte \"age\"\n",
        "\n",
        "X_data_train_copy = X_data_train.copy()\n",
        "X_data_test_copy = X_data_test.copy()\n",
        "X_data_train_copy[\"Age\"].fillna(\n",
        "    X_data_train_copy[\"Age\"].median(skipna=True), inplace=True\n",
        ")\n",
        "X_data_test_copy[\"Age\"].fillna(\n",
        "    X_data_test_copy[\"Age\"].median(skipna=True), inplace=True\n",
        ")\n",
        "\n",
        "x_train = np.array(X_data_train_copy[[\"Age\", \"Pclass\"]])\n",
        "x_test = np.array(X_data_test_copy[[\"Age\", \"Pclass\"]])\n",
        "model = LogisticRegression()\n",
        "model.fit(x_train, y_train)\n",
        "y_pred = model.predict(x_test)\n",
        "print(\"accuracy (accuracy_score): \" + str(accuracy_score(y_test, y_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxNwZco7wWgq"
      },
      "source": [
        "d.ii) Kategorische Variable\n",
        "\n",
        "Verwenden Sie die Funktion `pd.get_dummies` um die Variablen 'Pclass' and 'Sex' in numerische Werte umzuwandeln. Führen Sie nun eine logistische Regression durch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yu8UOcKAwWgq"
      },
      "source": [
        "e) Weitere Klassifikatoren. Neben der logistischen Regression, gibt es weitere Klassifikatoren. Der Random-Forest ist ein recht stabiler Klassifikator, was wäre die Performance von diesem Klassifikator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0eRJVGSwWgr"
      },
      "outputs": [],
      "source": [
        "# Hinweise zur Lösung\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier()\n",
        "# rf hat nun gleiches interface, wie die logistische Regression\n",
        "\n",
        "X_data_train_copy = X_data_train.copy()\n",
        "X_data_test_copy = X_data_test.copy()\n",
        "\n",
        "X_data_train_encoded = pd.get_dummies(X_data_train_copy, columns=[\"Pclass\", \"Sex\"])\n",
        "X_data_test_encoded = pd.get_dummies(X_data_test_copy, columns=[\"Pclass\", \"Sex\"])\n",
        "\n",
        "x_train = np.array(\n",
        "    X_data_train_encoded[[\"Pclass_1\", \"Pclass_2\", \"Pclass_3\", \"Sex_female\", \"Sex_male\"]]\n",
        ")\n",
        "x_test = np.array(\n",
        "    X_data_test_encoded[[\"Pclass_1\", \"Pclass_2\", \"Pclass_3\", \"Sex_female\", \"Sex_male\"]]\n",
        ")\n",
        "X_data_train_encoded\n",
        "\n",
        "# x_train.shape\n",
        "# x_test.shape\n",
        "model = LogisticRegression()\n",
        "model.fit(x_train, y_train)\n",
        "y_pred = model.predict(x_test)\n",
        "print(\"accuracy (accuracy_score): \" + str(accuracy_score(y_test, y_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oe_oIy11wWgr"
      },
      "source": [
        "f) [optional] Versuchen Sie weitere Features zu erzeugen und laden den besten Klassifikator auf Kaggle hoch. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "model.fit(x_train, y_train)\n",
        "y_pred = model.predict(x_test)\n",
        "print(\"accuracy (accuracy_score): \" + str(accuracy_score(y_test, y_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc49pWuewWgr"
      },
      "source": [
        "## Aufgabe 3 Titanic mit Neuronalen Netzen \n",
        "\n",
        "Hinweis: Diese Aufgabe kann erst nach der dritten Vorlesung in ML gemacht werden.\n",
        "\n",
        "Mit den gleichen Daten, wie in der Aufgabe 2 d. Erstellen Sie ein fully connected neural network und fitten es an die Ttrainingsdaten. Verwenden Sie mindestens zwei hidden Layer. Plotten Sie den Verlauf der Loss Kurve für die Trainings- und Validierungsdaten. Optional: Laden Sie Ihre beste Lösung auf Kaggle hoch. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYxfamTkwWgr",
        "outputId": "80a28e11-8256-4ab2-97ad-8f1d0ddda78e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 10)                50        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 61\n",
            "Trainable params: 61\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Aufteilung des Datensatzes in Trainings-, Validierungs- und Testdaten\n",
        "x_train = np.array(X_data_train[\"Pclass\"]).reshape(-1, 1)\n",
        "x_test = np.array(X_data_test[\"Pclass\"]).reshape(-1, 1)\n",
        "y_train = np.array(y_data_train)\n",
        "y_test = np.array(y_data_test)\n",
        "data_X = titanic_data\n",
        "data_y = titanic_data[\"Survived\"]\n",
        "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
        "    data_X, data_y, test_size=0.2, random_state=42\n",
        ")\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_trainval, y_trainval, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "X_train = pd.get_dummies(X_train.copy(), columns=[\"Pclass\", \"Sex\"])[\n",
        "    [\"Pclass_1\", \"Pclass_2\", \"Pclass_3\", \"Sex_female\", \"Sex_male\"]\n",
        "]\n",
        "X_val = pd.get_dummies(X_val.copy(), columns=[\"Pclass\", \"Sex\"])[\n",
        "    [\"Pclass_1\", \"Pclass_2\", \"Pclass_3\", \"Sex_female\", \"Sex_male\"]\n",
        "]\n",
        "X_test = pd.get_dummies(X_test.copy(), columns=[\"Pclass\", \"Sex\"])[\n",
        "    [\"Pclass_1\", \"Pclass_2\", \"Pclass_3\", \"Sex_female\", \"Sex_male\"]\n",
        "]\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_val = np.array(X_val)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "y_train = np.array(y_train)\n",
        "y_val = np.array(y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9M8BQdo5wWgs"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential()\n",
        "model.add(\n",
        "    keras.layers.Dense(10, activation=\"sigmoid\", batch_input_shape=(None, 5))\n",
        ")  # We have 4 input features\n",
        "model.add(keras.layers.Dense(10, activation=\"sigmoid\"))\n",
        "model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.01)  # Adadelta(learning_rate=0.001)\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(), optimizer=opt, metrics=[\"accuracy\"]\n",
        ")\n",
        "history = model.fit(X_train, y_train, epochs=50, validation_data=(X_val, y_val))\n",
        "evaluation = model.evaluate(X_test, y_test)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Evaluation: \" + str(evaluation))\n",
        "print(history.history.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(history.history[\"loss\"], label=\"Training loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"Validation loss\")\n",
        "plt.plot(history.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
        "plt.plot(history.history[\"accuracy\"], label=\"accuracy\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "ki_ml_blatt_1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
